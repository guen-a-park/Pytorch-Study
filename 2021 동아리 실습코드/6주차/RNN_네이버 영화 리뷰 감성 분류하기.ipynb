{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"RNN_네이버 영화 리뷰 감성 분류하기.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNmUiGKKexFStwD0WRfE0w7"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"QdPcdVIpVP0t"},"source":["# **1. 네이버 영화 리뷰 데이터에 대한 이해와 전처리**\r\n","[전처리할 데이터](https://github.com/e9t/nsmc/), 링크로 들어가서 ratings_train.txt, ratings_test.txt를 다운로드하면 모델에 필요한 데이터를 확인할 수 있습니다."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":380},"id":"XEherOWvSB7-","executionInfo":{"status":"error","timestamp":1613353198375,"user_tz":-540,"elapsed":1149,"user":{"displayName":"­박근아(엘텍공과대학 휴먼기계바이오공학부)","photoUrl":"","userId":"13921555510394140081"}},"outputId":"e184e666-dc44-4a6b-d3fa-0af9ddf7b81a"},"source":["import pandas as pd\r\n","import numpy as np\r\n","%matplotlib inline\r\n","import matplotlib.pyplot as plt\r\n","import re\r\n","import urllib.request\r\n","from konlpy.tag import Okt\r\n","from tensorflow.keras.preprocessing.text import Tokenizer\r\n","from tensorflow.keras.preprocessing.sequence import pad_sequences"],"execution_count":1,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-f9abdbb299df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkonlpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtag\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOkt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequence\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'konlpy'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"]}]},{"cell_type":"markdown","metadata":{"id":"xhXtTt5IVVfX"},"source":["## **1) 데이터 로드하기**"]},{"cell_type":"code","metadata":{"id":"WmRCK-BAThlR"},"source":["urllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt\", filename=\"ratings_train.txt\")\r\n","urllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings_test.txt\", filename=\"ratings_test.txt\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cK8HziQ5Thn7"},"source":["train_data = pd.read_table('ratings_train.txt')\r\n","test_data = pd.read_table('ratings_test.txt')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wWFoGAGCThqT"},"source":["print('훈련용 리뷰 개수 :',len(train_data)) # 훈련용 리뷰 개수 출력"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"O0i02bdFThs1"},"source":["train_data[:5] # 상위 5개 출력"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9NdqY11AThvK"},"source":["print('테스트용 리뷰 개수 :',len(test_data)) # 테스트용 리뷰 개수 출력"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wlgUUnwVThxO"},"source":["test_data[:5]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZSI3_s--Vjwe"},"source":["## **2) 데이터 정제하기**"]},{"cell_type":"code","metadata":{"id":"am1dVHW3Thz5"},"source":["train_data['document'].nunique(), train_data['label'].nunique()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SXdr9sOVTh2I"},"source":["train_data.drop_duplicates(subset=['document'], inplace=True) # document 열에서 중복인 내용이 있다면 중복 제거"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hBdlX4MzTh4r"},"source":["print('총 샘플의 수 :',len(train_data))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UmjjwLGRTh6U"},"source":["train_data['label'].value_counts().plot(kind = 'bar')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Urswp_ZeTh8m"},"source":["print(train_data.groupby('label').size().reset_index(name = 'count'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cQKBrHXQTh_C"},"source":["print(train_data.isnull().values.any())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WBeRLj6FTiBl"},"source":["print(train_data.isnull().sum())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"woKk4_cgTiEL"},"source":["train_data.loc[train_data.document.isnull()]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KGnhxjrrTiG0"},"source":["train_data = train_data.dropna(how = 'any') # Null 값이 존재하는 행 제거\r\n","print(train_data.isnull().values.any()) # Null 값이 존재하는지 확인"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zwWxN5aMTiJZ"},"source":["print(len(train_data))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fnUpNjB0TiLi"},"source":["text = 'do!!! you expect... people~ to~ read~ the FAQ, etc. and actually accept hard~! atheism?@@'\r\n","re.sub(r'[^a-zA-Z ]', '', text) #알파벳과 공백을 제외하고 모두 제거"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9Il4TIpsUIPG"},"source":["train_data['document'] = train_data['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\r\n","# 한글과 공백을 제외하고 모두 제거\r\n","train_data[:5]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nf-tPR_IUIUF"},"source":["train_data['document'].replace('', np.nan, inplace=True)\r\n","print(train_data.isnull().sum())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"u31lZTF2UIWh"},"source":["train_data.loc[train_data.document.isnull()][:5]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"49s1PHK9UIY6"},"source":["train_data = train_data.dropna(how = 'any')\r\n","print(len(train_data))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XTynT_AzUIdX"},"source":["test_data.drop_duplicates(subset = ['document'], inplace=True) # document 열에서 중복인 내용이 있다면 중복 제거\r\n","test_data['document'] = test_data['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\") # 정규 표현식 수행\r\n","test_data['document'].replace('', np.nan, inplace=True) # 공백은 Null 값으로 변경\r\n","test_data = test_data.dropna(how='any') # Null 값 제거\r\n","print('전처리 후 테스트용 샘플의 개수 :',len(test_data))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CFS-IdRwVt-p"},"source":["## **3) 토큰화**"]},{"cell_type":"code","metadata":{"id":"oalwTSM1UIgr"},"source":["stopwords = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QsKI27PWURhh"},"source":["okt = Okt()\r\n","okt.morphs('와 이런 것도 영화라고 차라리 뮤직비디오를 만드는 게 나을 뻔', stem = True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SfoaaMR2URqU"},"source":["X_train = []\r\n","for sentence in train_data['document']:\r\n","    temp_X = []\r\n","    temp_X = okt.morphs(sentence, stem=True) # 토큰화\r\n","    temp_X = [word for word in temp_X if not word in stopwords] # 불용어 제거\r\n","    X_train.append(temp_X)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bzRVNJ10URtI"},"source":["print(X_train[:3])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"X6DUEFagURvu"},"source":["X_test = []\r\n","for sentence in test_data['document']:\r\n","    temp_X = []\r\n","    temp_X = okt.morphs(sentence, stem=True) # 토큰화\r\n","    temp_X = [word for word in temp_X if not word in stopwords] # 불용어 제거\r\n","    X_test.append(temp_X)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6aVMOMsnVzVh"},"source":["## **4) 정수 인코딩**"]},{"cell_type":"code","metadata":{"id":"-LHU48WNURxi"},"source":["tokenizer = Tokenizer()\r\n","tokenizer.fit_on_texts(X_train)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vC47KoS_UR0C"},"source":["print(tokenizer.word_index)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BTXCu2jtUdGp"},"source":["threshold = 3\r\n","total_cnt = len(tokenizer.word_index) # 단어의 수\r\n","rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\r\n","total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\r\n","rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\r\n","\r\n","# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\r\n","for key, value in tokenizer.word_counts.items():\r\n","    total_freq = total_freq + value\r\n","\r\n","    # 단어의 등장 빈도수가 threshold보다 작으면\r\n","    if(value < threshold):\r\n","        rare_cnt = rare_cnt + 1\r\n","        rare_freq = rare_freq + value\r\n","\r\n","print('단어 집합(vocabulary)의 크기 :',total_cnt)\r\n","print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\r\n","print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\r\n","print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nhtKLSpiUdKw"},"source":["# 전체 단어 개수 중 빈도수 2이하인 단어 개수는 제거.\r\n","# 0번 패딩 토큰과 1번 OOV 토큰을 고려하여 +2\r\n","vocab_size = total_cnt - rare_cnt + 2\r\n","print('단어 집합의 크기 :',vocab_size)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Lel_Ah_FUdNS"},"source":["tokenizer = Tokenizer(vocab_size, oov_token = 'OOV') \r\n","tokenizer.fit_on_texts(X_train)\r\n","X_train = tokenizer.texts_to_sequences(X_train)\r\n","X_test = tokenizer.texts_to_sequences(X_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"J6RSxLQmUdQC"},"source":["print(X_train[:3])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Xr-hE0v0UdSk"},"source":["y_train = np.array(train_data['label'])\r\n","y_test = np.array(test_data['label'])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"t5diTN_gV45_"},"source":["## **5) 빈 샘플(empty samples) 제거**"]},{"cell_type":"code","metadata":{"id":"rYhWkBsdUdU0"},"source":["drop_train = [index for index, sentence in enumerate(X_train) if len(sentence) < 1]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wfgoGfxlUp8M"},"source":["# 빈 샘플들을 제거\r\n","X_train = np.delete(X_train, drop_train, axis=0)\r\n","y_train = np.delete(y_train, drop_train, axis=0)\r\n","print(len(X_train))\r\n","print(len(y_train))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OUVmBtUdV8K-"},"source":["## **6) 패딩**"]},{"cell_type":"code","metadata":{"id":"X5cc1f4YUqDD"},"source":["print('리뷰의 최대 길이 :',max(len(l) for l in X_train))\r\n","print('리뷰의 평균 길이 :',sum(map(len, X_train))/len(X_train))\r\n","plt.hist([len(s) for s in X_train], bins=50)\r\n","plt.xlabel('length of samples')\r\n","plt.ylabel('number of samples')\r\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1kfYP3coUqFl"},"source":["def below_threshold_len(max_len, nested_list):\r\n","  cnt = 0\r\n","  for s in nested_list:\r\n","    if(len(s) <= max_len):\r\n","        cnt = cnt + 1\r\n","  print('전체 샘플 중 길이가 %s 이하인 샘플의 비율: %s'%(max_len, (cnt / len(nested_list))*100))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"t_ShnpG-UqH6"},"source":["max_len = 30\r\n","below_threshold_len(max_len, X_train)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ol9QvfSDUvJd"},"source":["X_train = pad_sequences(X_train, maxlen = max_len)\r\n","X_test = pad_sequences(X_test, maxlen = max_len)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FFRYiP-yVKzw"},"source":["# **2. LSTM으로 네이버 영화 리뷰 감성 분류하기**"]},{"cell_type":"code","metadata":{"id":"L16zM8t2UvMK"},"source":["from tensorflow.keras.layers import Embedding, Dense, LSTM\r\n","from tensorflow.keras.models import Sequential\r\n","from tensorflow.keras.models import load_model\r\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cKly31ihUvPH"},"source":["model = Sequential()\r\n","model.add(Embedding(vocab_size, 100))\r\n","model.add(LSTM(128))\r\n","model.add(Dense(1, activation='sigmoid'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"p0Gg1fTnUvQ8"},"source":["es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)\r\n","mc = ModelCheckpoint('best_model.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"b92cnYROUvTO"},"source":["model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\r\n","history = model.fit(X_train, y_train, epochs=15, callbacks=[es, mc], batch_size=60, validation_split=0.2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2LVb2P_vU5Wv"},"source":["loaded_model = load_model('best_model.h5')\r\n","print(\"\\n 테스트 정확도: %.4f\" % (loaded_model.evaluate(X_test, y_test)[1]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nJ2ahHy0U5bF"},"source":["def sentiment_predict(new_sentence):\r\n","  new_sentence = okt.morphs(new_sentence, stem=True) # 토큰화\r\n","  new_sentence = [word for word in new_sentence if not word in stopwords] # 불용어 제거\r\n","  encoded = tokenizer.texts_to_sequences([new_sentence]) # 정수 인코딩\r\n","  pad_new = pad_sequences(encoded, maxlen = max_len) # 패딩\r\n","  score = float(loaded_model.predict(pad_new)) # 예측\r\n","  if(score > 0.5):\r\n","    print(\"{:.2f}% 확률로 긍정 리뷰입니다.\\n\".format(score * 100))\r\n","  else:\r\n","    print(\"{:.2f}% 확률로 부정 리뷰입니다.\\n\".format((1 - score) * 100))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eLKbColTU5dp"},"source":[""],"execution_count":null,"outputs":[]}]}